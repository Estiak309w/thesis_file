{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1:  READ DATA FILE & MAKE LIST OF EACH TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_slang = \"datafile/abusive_slang_stemmed.txt\"\n",
    "path_religious = \"datafile/abusive_religious_stemmed.txt\"\n",
    "path_personal_attack = \"datafile/abusive_personal_attack_stemmed.txt\"\n",
    "path_antifaminism = \"datafile/abusive_antifaminism_stemmed.txt\"\n",
    "path_political =  \"datafile/abusive_political_stemmed.txt\"\n",
    "\n",
    "\n",
    "def read_file(path):\n",
    "    sent =[]\n",
    "    sent.clear()\n",
    "    with open(path, \"r\",encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            sent.append(line)\n",
    "    return sent\n",
    "slang_sent = read_file(path_slang)\n",
    "religious_sent = read_file(path_religious)\n",
    "personal_attack_sent = read_file(path_personal_attack)\n",
    "political_sent = read_file(path_political)\n",
    "antifaminism_sent = read_file(path_antifaminism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿শয়তান অনেক বড় আলেম  আবেদ ছিল\n",
      "\n",
      "মাসুদ ছোট আলেম ছোট শয়তান\n",
      "\n",
      "তুই যে ইহুদিদ পয়দা ক কুকু\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(3):\n",
    "    print(religious_sent[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. REMOVE ALL BAD CHARECTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def digit_remover(text):\n",
    "    text = re.sub(r'[\\d]','',text)\n",
    "    text = re.sub(r'[?\\!\\t\\‛\\’\\(\\)\\.\\।]+','',text)\n",
    "    text = re.sub(r'[/\\-\\,]',' ',text)\n",
    "    text = text.rstrip(\"\\n\\r\")\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "হত্যাকাণ্ড খারাপ অদৃশ্য কাল্পনিক ধর্মের ধার্মিকদের \n"
     ]
    }
   ],
   "source": [
    "print(digit_remover(\"হত্যাকাণ্ড/খারাপ,অদৃশ্য-কাল্পনিক,ধর্মের/ধার্মিকদের,0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remover(sent):\n",
    "    for i in range(len(sent)):\n",
    "        sent[i] = digit_remover(sent[i])\n",
    "    return sent\n",
    "slang_sent = remover(slang_sent)\n",
    "religious_sent = remover(religious_sent)\n",
    "personal_attack_sent = remover(personal_attack_sent)\n",
    "political_sent = remover(political_sent)\n",
    "antifaminism_sent = remover(antifaminism_sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿খালেদা ধ্বংস প্রতিক\n",
      "ভাইয়ে সুনেন জেরকম নেন্ত্রী সেরকম বকতব্য পগল মুগি নেএরি\n",
      "সবাই নাইছা হাছিনা আপা বাতাস দেন আপা খালি গরম লাগে\n",
      "আওয়ামী লীগ মানেই পাগরেল দল\n",
      "হাছিনা বসতি মহিলাদ চেয়ে  নিচু মন মানুষ\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(political_sent[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADD COLUMN AND LABEL EACH TYPE OF DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "slang_df = pd.DataFrame({'col':slang_sent})\n",
    "slang_df['label'] = 1\n",
    "religious_df = pd.DataFrame({'col':religious_sent})\n",
    "religious_df['label'] = 2\n",
    "personal_attack_df = pd.DataFrame({'col':personal_attack_sent})\n",
    "personal_attack_df['label'] = 3\n",
    "political_df = pd.DataFrame({'col':political_sent})\n",
    "political_df['label'] = 4\n",
    "antifaminism_df = pd.DataFrame({'col':antifaminism_sent})\n",
    "antifaminism_df['label'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attack_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCATENATE EACH TYPE OF DATA AND SUFFLE THEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [slang_df, religious_df,personal_attack_df,political_df,antifaminism_df]\n",
    "result = pd.concat(frames,ignore_index=True)\n",
    "#suffle the data frame\n",
    "result = result.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLIT DATA INTO TRAIN AND TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = result['col']\n",
    "y = result['label']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = 1,test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2498, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    1051\n",
       "1     419\n",
       "2     415\n",
       "5     338\n",
       "4     275\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#  REPRESENTING TEXT AS NUMERICAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and instantiate tfidfVECTORIZER (with the default parameters)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(tokenizer=lambda a: a.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn the 'vocabulary' of the training data (occurs in-place)\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2632, 5261) (2632,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE('minority')\n",
    "X_sm,y_sm = smote.fit_sample(X_train_dtm,y_train)\n",
    "print(X_sm.shape,y_sm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPLY MULTINOMIAL NAIVE BAYES ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and instantiate a Multinomial Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB(alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm (timing it with an IPython \"magic command\")\n",
    "%time nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.642"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = [\"ভাইজান কপালে সুধু অপু বুবলি মত ফ্লপ নায়িকা\"]\n",
    "input_sentence_dtm = vect.transform(input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "celebrity_abusive_sentence\n"
     ]
    }
   ],
   "source": [
    "typo = nb.predict(input_sentence_dtm)\n",
    "def get_result(result):\n",
    "    if(typo==0):\n",
    "        return (\"slang sentence\")\n",
    "    \n",
    "    elif(typo==1):\n",
    "        return(\"religious_abusive_sentence\")\n",
    "    else:\n",
    "        return(\"celebrity_abusive_sentence\")\n",
    "\n",
    "print(get_result(typo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPLY GRID SEARCH ON MULTINOMIAL NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': [0.0001, 0.001, 0.01, 1]}\n"
     ]
    }
   ],
   "source": [
    "alphas = [0.0001,0.001,0.01,1]\n",
    "# create a parameter grid: map the parameter names to the values that should be searched\n",
    "param_grid = dict(alpha= alphas)\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'alpha': [0.0001, 0.001, 0.01, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dtm = vect.fit_transform(X)\n",
    "# instantiate and fit the grid\n",
    "grid = GridSearchCV(nb, param_grid, cv=10, scoring='accuracy', return_train_score=False)\n",
    "grid.fit(X_dtm, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6285028022417934\n",
      "{'alpha': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPLY LINEAR SVC CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svc = LinearSVC(multi_class='ovr',max_iter=800,tol=0.0001,random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.fit(X_train_dtm, y_train)\n",
    "y_pred_class_svc = svc.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.694"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_pred_class_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "celebrity_abusive_sentence\n"
     ]
    }
   ],
   "source": [
    "typo_svc = svc.predict(input_sentence_dtm)\n",
    "\n",
    "def get_result(result):\n",
    "    if(typo==0):\n",
    "        return (\"slang sentence\")\n",
    "    \n",
    "    elif(typo==1):\n",
    "        return(\"religious_abusive_sentence\")\n",
    "    else:\n",
    "        return(\"celebrity_abusive_sentence\")\n",
    "\n",
    "print(get_result(typo_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.42      0.51        90\n",
      "           2       0.82      0.70      0.75        79\n",
      "           3       0.64      0.85      0.73       204\n",
      "           4       0.98      0.73      0.83        62\n",
      "           5       0.62      0.55      0.59        65\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       500\n",
      "   macro avg       0.74      0.65      0.68       500\n",
      "weighted avg       0.71      0.69      0.69       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the classification report\n",
    "print(metrics.classification_report(y_test, y_pred_class_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=800,\n",
       "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
       "     verbose=0)>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPLY GRID SEARCH ON LINEARSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#penalties = ['l1','l2']\n",
    "#losses = ['hinge','squared_hinge']\n",
    "multi_classes = ['ovr','crammer_singer']\n",
    "max_iters = [800,1000,1300]\n",
    "tols = [0.0001,0.001,0.01]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'multi_class': ['ovr', 'crammer_singer'], 'max_iter': [800, 1000, 1300], 'tol': [0.0001, 0.001, 0.01]}\n"
     ]
    }
   ],
   "source": [
    "# create a parameter grid: map the parameter names to the values that should be searched\n",
    "param_grid = dict(multi_class = multi_classes ,max_iter=max_iters,tol=tols)\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\estia\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=800,\n",
       "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
       "     verbose=0),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'multi_class': ['ovr', 'crammer_singer'], 'max_iter': [800, 1000, 1300], 'tol': [0.0001, 0.001, 0.01]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dtm = vect.fit_transform(X)\n",
    "# instantiate and fit the grid\n",
    "grid = GridSearchCV(svc, param_grid, cv=10, scoring='accuracy', return_train_score=False)\n",
    "grid.fit(X_dtm, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.682946</td>\n",
       "      <td>0.024810</td>\n",
       "      <td>{'max_iter': 800, 'multi_class': 'ovr', 'tol':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.682946</td>\n",
       "      <td>0.024810</td>\n",
       "      <td>{'max_iter': 800, 'multi_class': 'ovr', 'tol':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.682546</td>\n",
       "      <td>0.024863</td>\n",
       "      <td>{'max_iter': 800, 'multi_class': 'ovr', 'tol':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.681345</td>\n",
       "      <td>0.030183</td>\n",
       "      <td>{'max_iter': 800, 'multi_class': 'crammer_sing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.681345</td>\n",
       "      <td>0.030183</td>\n",
       "      <td>{'max_iter': 800, 'multi_class': 'crammer_sing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.681345</td>\n",
       "      <td>0.030183</td>\n",
       "      <td>{'max_iter': 800, 'multi_class': 'crammer_sing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.682946</td>\n",
       "      <td>0.024810</td>\n",
       "      <td>{'max_iter': 1000, 'multi_class': 'ovr', 'tol'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.682946</td>\n",
       "      <td>0.024810</td>\n",
       "      <td>{'max_iter': 1000, 'multi_class': 'ovr', 'tol'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.682546</td>\n",
       "      <td>0.024863</td>\n",
       "      <td>{'max_iter': 1000, 'multi_class': 'ovr', 'tol'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.681345</td>\n",
       "      <td>0.030183</td>\n",
       "      <td>{'max_iter': 1000, 'multi_class': 'crammer_sin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.681345</td>\n",
       "      <td>0.030183</td>\n",
       "      <td>{'max_iter': 1000, 'multi_class': 'crammer_sin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.681345</td>\n",
       "      <td>0.030183</td>\n",
       "      <td>{'max_iter': 1000, 'multi_class': 'crammer_sin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.682946</td>\n",
       "      <td>0.024810</td>\n",
       "      <td>{'max_iter': 1300, 'multi_class': 'ovr', 'tol'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.682946</td>\n",
       "      <td>0.024810</td>\n",
       "      <td>{'max_iter': 1300, 'multi_class': 'ovr', 'tol'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.682546</td>\n",
       "      <td>0.024863</td>\n",
       "      <td>{'max_iter': 1300, 'multi_class': 'ovr', 'tol'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.681345</td>\n",
       "      <td>0.030183</td>\n",
       "      <td>{'max_iter': 1300, 'multi_class': 'crammer_sin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.681345</td>\n",
       "      <td>0.030183</td>\n",
       "      <td>{'max_iter': 1300, 'multi_class': 'crammer_sin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.681345</td>\n",
       "      <td>0.030183</td>\n",
       "      <td>{'max_iter': 1300, 'multi_class': 'crammer_sin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score  std_test_score  \\\n",
       "0          0.682946        0.024810   \n",
       "1          0.682946        0.024810   \n",
       "2          0.682546        0.024863   \n",
       "3          0.681345        0.030183   \n",
       "4          0.681345        0.030183   \n",
       "5          0.681345        0.030183   \n",
       "6          0.682946        0.024810   \n",
       "7          0.682946        0.024810   \n",
       "8          0.682546        0.024863   \n",
       "9          0.681345        0.030183   \n",
       "10         0.681345        0.030183   \n",
       "11         0.681345        0.030183   \n",
       "12         0.682946        0.024810   \n",
       "13         0.682946        0.024810   \n",
       "14         0.682546        0.024863   \n",
       "15         0.681345        0.030183   \n",
       "16         0.681345        0.030183   \n",
       "17         0.681345        0.030183   \n",
       "\n",
       "                                               params  \n",
       "0   {'max_iter': 800, 'multi_class': 'ovr', 'tol':...  \n",
       "1   {'max_iter': 800, 'multi_class': 'ovr', 'tol':...  \n",
       "2   {'max_iter': 800, 'multi_class': 'ovr', 'tol':...  \n",
       "3   {'max_iter': 800, 'multi_class': 'crammer_sing...  \n",
       "4   {'max_iter': 800, 'multi_class': 'crammer_sing...  \n",
       "5   {'max_iter': 800, 'multi_class': 'crammer_sing...  \n",
       "6   {'max_iter': 1000, 'multi_class': 'ovr', 'tol'...  \n",
       "7   {'max_iter': 1000, 'multi_class': 'ovr', 'tol'...  \n",
       "8   {'max_iter': 1000, 'multi_class': 'ovr', 'tol'...  \n",
       "9   {'max_iter': 1000, 'multi_class': 'crammer_sin...  \n",
       "10  {'max_iter': 1000, 'multi_class': 'crammer_sin...  \n",
       "11  {'max_iter': 1000, 'multi_class': 'crammer_sin...  \n",
       "12  {'max_iter': 1300, 'multi_class': 'ovr', 'tol'...  \n",
       "13  {'max_iter': 1300, 'multi_class': 'ovr', 'tol'...  \n",
       "14  {'max_iter': 1300, 'multi_class': 'ovr', 'tol'...  \n",
       "15  {'max_iter': 1300, 'multi_class': 'crammer_sin...  \n",
       "16  {'max_iter': 1300, 'multi_class': 'crammer_sin...  \n",
       "17  {'max_iter': 1300, 'multi_class': 'crammer_sin...  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the results\n",
    "pd.DataFrame(grid.cv_results_)[['mean_test_score', 'std_test_score', 'params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6829463570856685\n",
      "{'max_iter': 800, 'multi_class': 'ovr', 'tol': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPLY LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logit = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\estia\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\estia\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logit.fit(X_train_dtm, y_train)\n",
    "y_pred_class_logit = logit.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.582"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_pred_class_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "celebrity_abusive_sentence\n"
     ]
    }
   ],
   "source": [
    "typo_logit = logit.predict(input_sentence_dtm)\n",
    "print(get_result(typo_logit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPLY RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "randomf = RandomForestClassifier(n_estimators=1000,max_depth=50)\n",
    "randomf.fit(X_train_dtm, y_train)\n",
    "y_pred_class_randomf = randomf.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.582"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_pred_class_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "celebrity_abusive_sentence\n"
     ]
    }
   ],
   "source": [
    "typo_randomf = logit.predict(input_sentence_dtm)\n",
    "print(get_result(typo_randomf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPLY STOCHASTIC GRADIENT DECENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
