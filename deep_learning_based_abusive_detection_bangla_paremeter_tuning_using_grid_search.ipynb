{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GOOD LUCK\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def pad_sequences(sequences, maxlen=2000):\n",
    "    for s in sequences:\n",
    "        if len(s) == 0: yield np.zeros((1, maxlen), dtype='int32')\n",
    "        else:\n",
    "          s = np.array(s, dtype='int32')\n",
    "          yield np.expand_dims(np.pad(s[:maxlen], (0, max(0, maxlen - len(s))), 'constant'), axis=0)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_slang = \"datafile/abusive_slang_stemmed.txt\"\n",
    "path_religious = \"datafile/abusive_religious_stemmed.txt\"\n",
    "path_personal_attack = \"datafile/abusive_personal_attack_stemmed.txt\"\n",
    "path_antifaminism = \"datafile/abusive_antifaminism_stemmed.txt\"\n",
    "path_political =  \"datafile/abusive_political_stemmed.txt\"\n",
    "\n",
    "\n",
    "def read_file(path):\n",
    "    sent =[]\n",
    "    sent.clear()\n",
    "    with open(path, \"r\",encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            sent.append(line)\n",
    "    return sent\n",
    "slang_sent = read_file(path_slang)\n",
    "religious_sent = read_file(path_religious)\n",
    "personal_attack_sent = read_file(path_personal_attack)\n",
    "political_sent = read_file(path_political)\n",
    "antifaminism_sent = read_file(path_antifaminism)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def digit_remover(text):\n",
    "    text = re.sub(r'[\\d]','',text)\n",
    "    text = re.sub(r'[?\\!\\t\\‛\\’\\(\\)\\.\\।]+','',text)\n",
    "    text = re.sub(r'[/\\-\\,]',' ',text)\n",
    "    text = text.rstrip(\"\\n\\r\")\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remover(sent):\n",
    "    for i in range(len(sent)):\n",
    "        sent[i] = digit_remover(sent[i])\n",
    "    return sent\n",
    "slang_sent = remover(slang_sent)\n",
    "religious_sent = remover(religious_sent)\n",
    "personal_attack_sent = remover(personal_attack_sent)\n",
    "political_sent = remover(political_sent)\n",
    "antifaminism_sent = remover(antifaminism_sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slang_df = pd.DataFrame({'col':slang_sent})\n",
    "slang_df['label'] = 0\n",
    "religious_df = pd.DataFrame({'col':religious_sent})\n",
    "religious_df['label'] = 1\n",
    "personal_attack_df = pd.DataFrame({'col':personal_attack_sent})\n",
    "personal_attack_df['label'] = 2\n",
    "political_df = pd.DataFrame({'col':political_sent})\n",
    "political_df['label'] = 3\n",
    "antifaminism_df = pd.DataFrame({'col':antifaminism_sent})\n",
    "antifaminism_df['label'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [slang_df, religious_df,personal_attack_df,political_df,antifaminism_df]\n",
    "result = pd.concat(frames,ignore_index=True)\n",
    "#suffle the data frame\n",
    "result = result.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = result['col']\n",
    "y = result['label']\n",
    "y = to_categorical(result['label'], num_classes=5)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = 42,test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = Tokenizer()\n",
    "tokenize.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tokenize.texts_to_sequences(X)\n",
    "#X_test = tokenize.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lenght = max([len(s.split()) for s in result['col']])\n",
    "X = pad_sequences(X, max_lenght)\n",
    "#X_test = pad_sequences(X_test, max_lenght)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to cope up with variation of classes and small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2642, 124) (2642, 5)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE('minority')\n",
    "X_sm,y_sm = smote.fit_sample(X_train,y_train)\n",
    "print(X_sm.shape,y_sm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tune batch size and number of epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    EMBEDDING_DIM = 100\n",
    "    unknown = len(tokenize.word_index)+1\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(unknown, EMBEDDING_DIM, input_length=max_lenght))\n",
    "    model.add(LSTM(units=128, dropout=0.1, recurrent_dropout=0.2 ))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_classes = ['ovr','crammer_singer']\n",
    "batch_size = [64,100,128]\n",
    "epochs = [7]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid.cv_results_)[['mean_test_score', 'std_test_score', 'params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the best model\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I choose to build 3 hidden layers\n",
    "EMBEDDING_DIM = 100\n",
    "unknown = len(tokenize.word_index)+1\n",
    "model = Sequential()\n",
    "model.add(Embedding(unknown, EMBEDDING_DIM, input_length=max_lenght))\n",
    "model.add(LSTM(units=128, dropout=0.1, recurrent_dropout=0.2 ))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 124, 100)          532300    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 650,193\n",
      "Trainable params: 650,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1998, 5)\n",
      "(1998, 124)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "1998/1998 [==============================] - 18s 9ms/step - loss: 0.0189 - acc: 0.9935\n",
      "Epoch 2/7\n",
      "1998/1998 [==============================] - 20s 10ms/step - loss: 0.0149 - acc: 0.9960\n",
      "Epoch 3/7\n",
      "1998/1998 [==============================] - 17s 9ms/step - loss: 0.0122 - acc: 0.9955\n",
      "Epoch 4/7\n",
      "1998/1998 [==============================] - 18s 9ms/step - loss: 0.0116 - acc: 0.9970\n",
      "Epoch 5/7\n",
      "1998/1998 [==============================] - 21s 10ms/step - loss: 0.0088 - acc: 0.9970\n",
      "Epoch 6/7\n",
      "1998/1998 [==============================] - 18s 9ms/step - loss: 0.0108 - acc: 0.9965\n",
      "Epoch 7/7\n",
      "1998/1998 [==============================] - 18s 9ms/step - loss: 0.0074 - acc: 0.9980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c1261b0d30>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit(X_sm, y_sm, batch_size=128, epochs=7, verbose=1)\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=7, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = model.predict_classes(X_test)\n",
    "final_pred= to_categorical(final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.604"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 1s 3ms/step\n",
      "0.6040000033378601\n"
     ]
    }
   ],
   "source": [
    "score,acc = model.evaluate(X_test,y_test,batch_size=128,verbose=1)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
