{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1:  READ DATA FILE & MAKE LIST OF EACH TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_slang = \"datafile/abusive_slang.txt\"\n",
    "path_religious = \"datafile/abusive_religious.txt\"\n",
    "path_personal_attack = \"datafile/abusive_personal_attack.txt\"\n",
    "path_antifaminism = \"datafile/abusive_antifaminism.txt\"\n",
    "path_political =  \"datafile/abusive_political.txt\"\n",
    "\n",
    "\n",
    "def read_file(path):\n",
    "    sent =[]\n",
    "    sent.clear()\n",
    "    with open(path, \"r\",encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            sent.append(line)\n",
    "    return sent\n",
    "slang_sent = read_file(path_slang)\n",
    "religious_sent = read_file(path_religious)\n",
    "personal_attack_sent = read_file(path_personal_attack)\n",
    "political_sent = read_file(path_political)\n",
    "antifaminism_sent = read_file(path_antifaminism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿শয়তান অনেক বড় আলেম ও আবেদ ছিল\n",
      "\n",
      "মাসুদ ছোট আলেম ছোট শয়তান\n",
      "\n",
      "তুই যে ইহুদিদের পয়দা করা কুকুর\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(3):\n",
    "    print(religious_sent[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. REMOVE ALL BAD CHARECTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def digit_remover(text):\n",
    "    text = re.sub(r'[\\d]','',text)\n",
    "    text = re.sub(r'[?\\!\\t\\‛\\’\\(\\)\\.\\।]+','',text)\n",
    "    text = re.sub(r'[/\\-\\,]',' ',text)\n",
    "    text = text.rstrip(\"\\n\\r\")\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "হত্যাকাণ্ড খারাপ অদৃশ্য কাল্পনিক ধর্মের ধার্মিকদের \n"
     ]
    }
   ],
   "source": [
    "print(digit_remover(\"হত্যাকাণ্ড/খারাপ,অদৃশ্য-কাল্পনিক,ধর্মের/ধার্মিকদের,0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remover(sent):\n",
    "    for i in range(len(sent)):\n",
    "        sent[i] = digit_remover(sent[i])\n",
    "    return sent\n",
    "slang_sent = remover(slang_sent)\n",
    "religious_sent = remover(religious_sent)\n",
    "personal_attack_sent = remover(personal_attack_sent)\n",
    "political_sent = remover(political_sent)\n",
    "antifaminism_sent = remover(antifaminism_sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿তোদের কে বাশ দিব\n",
      "টুপি টা খুল পান্জাবি টা ও খুল\n",
      "মদ খা মদ খা মদ তর জন্য এখন আলাল চি চি চি মুসলীম এর জন্য হারাম জাতী সব জানে তুই দালালী করতেছত টাকার জন্য মাগীর পুলা তুই নাস্তীক \n",
      "ফকিন্নীর বাচ্চা যাদের খাবারগুলো খেয়েছিস দান খয়রাতগুলো খেয়েছিস তার জবাব তোকে দিতে হবে ফকিন্নীর বাচ্চা\n",
      "ফকিন্নী শালা নেরাকুত্তা\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(personal_attack_sent[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADD COLUMN AND LABEL EACH TYPE OF DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "slang_df = pd.DataFrame({'col':slang_sent})\n",
    "slang_df['label'] = 1\n",
    "religious_df = pd.DataFrame({'col':religious_sent})\n",
    "religious_df['label'] = 2\n",
    "personal_attack_df = pd.DataFrame({'col':personal_attack_sent})\n",
    "personal_attack_df['label'] = 3\n",
    "political_df = pd.DataFrame({'col':political_sent})\n",
    "political_df['label'] = 4\n",
    "antifaminism_df = pd.DataFrame({'col':antifaminism_sent})\n",
    "antifaminism_df['label'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attack_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCATENATE EACH TYPE OF DATA AND SUFFLE THEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [slang_df, religious_df,personal_attack_df,political_df,antifaminism_df]\n",
    "result = pd.concat(frames,ignore_index=True)\n",
    "#suffle the data frame\n",
    "result = result.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLIT DATA INTO TRAIN AND TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = result['col']\n",
    "y = result['label']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = 1,test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2504, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  REPRESENTING TEXT AS NUMERICAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and instantiate tfidfVECTORIZER (with the default parameters)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(tokenizer=lambda a: a.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn the 'vocabulary' of the training data (occurs in-place)\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPLY MULTINOMIAL NAIVE BAYES ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and instantiate a Multinomial Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB(alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm (timing it with an IPython \"magic command\")\n",
    "%time nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6487025948103793"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPLY LINEAR SVC CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svc = LinearSVC()\n",
    "svc.fit(X_train_dtm, y_train)\n",
    "y_pred_class_svc = svc.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_pred_class_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPLY LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logit = LogisticRegression()\n",
    "logit.fit(X_train_dtm, y_train)\n",
    "y_pred_class_logit = logit.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5868263473053892"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_pred_class_logit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPLY RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "randomf = RandomForestClassifier(n_estimators=1000,max_depth=50)\n",
    "randomf.fit(X_train_dtm, y_train)\n",
    "y_pred_class_randomf = randomf.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5868263473053892"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_pred_class_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
