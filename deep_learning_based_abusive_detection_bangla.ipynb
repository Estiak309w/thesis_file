{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#GOOD LUCK\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def pad_sequences(sequences, maxlen=2000):\\n    for s in sequences:\\n        if len(s) == 0: yield np.zeros((1, maxlen), dtype='int32')\\n        else:\\n          s = np.array(s, dtype='int32')\\n          yield np.expand_dims(np.pad(s[:maxlen], (0, max(0, maxlen - len(s))), 'constant'), axis=0)\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def pad_sequences(sequences, maxlen=2000):\n",
    "    for s in sequences:\n",
    "        if len(s) == 0: yield np.zeros((1, maxlen), dtype='int32')\n",
    "        else:\n",
    "          s = np.array(s, dtype='int32')\n",
    "          yield np.expand_dims(np.pad(s[:maxlen], (0, max(0, maxlen - len(s))), 'constant'), axis=0)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_slang = \"datafile/abusive_slang_stemmed.txt\"\n",
    "path_religious = \"datafile/abusive_religious_stemmed.txt\"\n",
    "path_personal_attack = \"datafile/abusive_personal_attack_stemmed.txt\"\n",
    "path_antifaminism = \"datafile/abusive_antifaminism_stemmed.txt\"\n",
    "path_political =  \"datafile/abusive_political_stemmed.txt\"\n",
    "\n",
    "\n",
    "def read_file(path):\n",
    "    sent =[]\n",
    "    sent.clear()\n",
    "    with open(path, \"r\",encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            sent.append(line)\n",
    "    return sent\n",
    "slang_sent = read_file(path_slang)\n",
    "religious_sent = read_file(path_religious)\n",
    "personal_attack_sent = read_file(path_personal_attack)\n",
    "political_sent = read_file(path_political)\n",
    "antifaminism_sent = read_file(path_antifaminism)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def digit_remover(text):\n",
    "    text = re.sub(r'[\\d]','',text)\n",
    "    text = re.sub(r'[?\\!\\t\\‛\\’\\(\\)\\.\\।]+','',text)\n",
    "    text = re.sub(r'[/\\-\\,]',' ',text)\n",
    "    text = text.rstrip(\"\\n\\r\")\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remover(sent):\n",
    "    for i in range(len(sent)):\n",
    "        sent[i] = digit_remover(sent[i])\n",
    "    return sent\n",
    "slang_sent = remover(slang_sent)\n",
    "religious_sent = remover(religious_sent)\n",
    "personal_attack_sent = remover(personal_attack_sent)\n",
    "political_sent = remover(political_sent)\n",
    "antifaminism_sent = remover(antifaminism_sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "slang_df = pd.DataFrame({'col':slang_sent})\n",
    "slang_df['label'] = 0\n",
    "religious_df = pd.DataFrame({'col':religious_sent})\n",
    "religious_df['label'] = 1\n",
    "personal_attack_df = pd.DataFrame({'col':personal_attack_sent})\n",
    "personal_attack_df['label'] = 2\n",
    "political_df = pd.DataFrame({'col':political_sent})\n",
    "political_df['label'] = 3\n",
    "antifaminism_df = pd.DataFrame({'col':antifaminism_sent})\n",
    "antifaminism_df['label'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [slang_df, religious_df,personal_attack_df,political_df,antifaminism_df]\n",
    "result = pd.concat(frames,ignore_index=True)\n",
    "#suffle the data frame\n",
    "result = result.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "X = result['col']\n",
    "y = result['label']\n",
    "y = to_categorical(result['label'], num_classes=5)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = seed,test_size=.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = Tokenizer()\n",
    "tokenize.fit_on_texts(X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenize.texts_to_sequences(X_train)\n",
    "X_test = tokenize.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lenght = max([len(s.split()) for s in result['col']])\n",
    "X_train = pad_sequences(X_train, max_lenght)\n",
    "X_test = pad_sequences(X_test, max_lenght)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2947, 124) (2947, 5)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE('minority')\n",
    "X_sm,y_sm = smote.fit_sample(X_train,y_train)\n",
    "print(X_sm.shape,y_sm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I choose to build 3 hidden layers\n",
    "EMBEDDING_DIM = 100\n",
    "unknown = len(tokenize.word_index)+1\n",
    "model = Sequential()\n",
    "model.add(Embedding(unknown, EMBEDDING_DIM, input_length=max_lenght))\n",
    "model.add(LSTM(units=128, dropout=0.1, recurrent_dropout=0.2 ))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 124, 100)          568900    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 686,793\n",
      "Trainable params: 686,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2248, 5)\n",
      "(2248, 124)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2248/2248 [==============================] - 29s 13ms/step - loss: 1.5040 - acc: 0.4133\n",
      "Epoch 2/10\n",
      "2248/2248 [==============================] - 28s 13ms/step - loss: 1.3744 - acc: 0.4391\n",
      "Epoch 3/10\n",
      "2248/2248 [==============================] - 30s 13ms/step - loss: 1.0154 - acc: 0.6379\n",
      "Epoch 4/10\n",
      "2248/2248 [==============================] - 28s 13ms/step - loss: 0.6500 - acc: 0.7998\n",
      "Epoch 5/10\n",
      "2248/2248 [==============================] - 28s 13ms/step - loss: 0.3481 - acc: 0.9141\n",
      "Epoch 6/10\n",
      "2248/2248 [==============================] - 30s 13ms/step - loss: 0.1797 - acc: 0.9520\n",
      "Epoch 7/10\n",
      "2248/2248 [==============================] - 26s 12ms/step - loss: 0.1034 - acc: 0.9729\n",
      "Epoch 8/10\n",
      "2248/2248 [==============================] - 25s 11ms/step - loss: 0.0676 - acc: 0.9818\n",
      "Epoch 9/10\n",
      "2248/2248 [==============================] - 23s 10ms/step - loss: 0.0466 - acc: 0.9858\n",
      "Epoch 10/10\n",
      "2248/2248 [==============================] - 27s 12ms/step - loss: 0.0329 - acc: 0.9898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1775f0f36a0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit(X_sm, y_sm, batch_size=64, epochs=7, verbose=1)\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = model.predict_classes(X_test)\n",
    "final_pred= to_categorical(final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.648"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 6ms/step\n",
      "0.6480000066757202\n"
     ]
    }
   ],
   "source": [
    "score,acc = model.evaluate(X_test,y_test,batch_size=64,verbose=1)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.43      0.39        42\n",
      "           1       0.88      0.62      0.73        45\n",
      "           2       0.69      0.69      0.69       108\n",
      "           3       0.93      0.81      0.86        31\n",
      "           4       0.52      0.71      0.60        24\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       250\n",
      "   macro avg       0.67      0.65      0.65       250\n",
      "weighted avg       0.68      0.65      0.66       250\n",
      " samples avg       0.65      0.65      0.65       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the classification report\n",
    "print(metrics.classification_report(y_test, final_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
